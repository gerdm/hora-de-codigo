{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hora de C√≥digo: Ense√±ando a Aprender\n",
    "## El pipeline de data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos nos encomiendan la tarea de escribir una sequela para el Libro Don Quixote de la Mancha. Debido a nuestra poca experiencia en obras literarias, y la inifinitesimal probabilidad de que hayamos le√≠do la obra en su totalidad, \n",
    "\n",
    "Para lograr el objetivo, ser√° necesario dividir la tarea en tres partes\n",
    "\n",
    "* **An√°lisis**\n",
    "* **Modelaci√≥n**\n",
    "* **Producci√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from unidecode import unidecode\n",
    "from collections import deque\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis\n",
    "## Primeros Pasos\n",
    "\n",
    "Con el fin de escribir una sequela, lo primero que realizaremos ser√° entender la primera parte del libro.\n",
    "\n",
    "**¬øDe qu√© manera podemos obtener acceeso a la obra?**  \n",
    "1. Transcribir el libro a nuestra computadora \n",
    "2. Buscar el libro en l√≠nea, copiarlo y pegarlo en alg√∫n lugar para tener acceso a este\n",
    "3. Acceder directamente al libro y no tener que copiar y pegar nada (üëç)\n",
    "\n",
    "Para nuestra suerte, la p√°gina _[Project Gutemberg](http://www.gutenberg.org)_ ofrece libros gratuitos en l√≠nea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.gutenberg.org/cache/epub/2000/pg2000.txt\"\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = r.text\n",
    "init_book = corpus.find(\"En un lugar de la Mancha\")\n",
    "end_book = corpus.find(\"End of Project Gutenberg's\")\n",
    "corpus = corpus[init_book: end_book]\n",
    "corpus = unidecode(corpus.replace(\"\\r\\n\", \" \"))\n",
    "corpus = re.sub(\"[^\\w\\s]\", \"\", corpus).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en un lugar de la mancha de cuyo nombre no quiero acordarme no ha mucho tiempo que vivia un hidalgo de los de lanza en astillero adarga antigua rocin flaco y galgo corredor una olla de algo mas vaca que carnero salpicon las mas noches duelos y quebrantos los sabados lantejas los viernes algun palomino de anadidura los domingos consumian las tres partes de su hacienda el resto della concluian sayo de velarte calzas de velludo para las fiestas con sus pantuflos de lo mesmo y los dias de entreseman'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en', 'un', 'lugar', 'de', 'la', 'mancha', 'de', 'cuyo', 'nombre', 'no']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text.split()\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look to make a sequence of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('que', 21246),\n",
       " ('de', 18031),\n",
       " ('y', 17980),\n",
       " ('la', 10224),\n",
       " ('a', 9718),\n",
       " ('el', 9346),\n",
       " ('en', 8109),\n",
       " ('no', 6275),\n",
       " ('se', 5025),\n",
       " ('los', 4701)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter = Counter(tokens)\n",
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = []\n",
    "for w0, w1 in zip(tokens[0:-1], tokens[1:len(tokens)]):\n",
    "    element = (w0, w1)\n",
    "    elements.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('don', 'quijote'), 2149),\n",
       " (('de', 'la'), 2052),\n",
       " (('lo', 'que'), 1535),\n",
       " (('que', 'no'), 1284),\n",
       " (('en', 'el'), 1042),\n",
       " (('de', 'los'), 965),\n",
       " (('que', 'se'), 939),\n",
       " (('en', 'la'), 934),\n",
       " (('de', 'su'), 900),\n",
       " (('a', 'la'), 900)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = Counter(elements)\n",
    "bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora tenemos lo _bigram_ m√°s com√∫nes, ¬øde qu√© manera podemos conocer los _bigrams_ que empiecen con ciertas palabras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('don', 'quijote') 2149\n",
      "('don', 'fernando') 131\n",
      "('don', 'antonio') 62\n",
      "('don', 'luis') 36\n"
     ]
    }
   ],
   "source": [
    "topv = sorted(filter(lambda w: w[0] == \"don\", bigrams),\n",
    "                     key=lambda w: bigrams[w])[:-5:-1]\n",
    "for v in topv:\n",
    "    print(v, bigrams[v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øDe qu√© manera podr√≠amos calcular la probabilidad de que Cervantes haya escrito `\"quijote\"` dado que la palabra precedente a esta es `\"don\"`?\n",
    "\n",
    "$$\n",
    "    \\mathbb{P}(\\texttt{\"quijote\"} | \\texttt{\"don\"})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981421272642824\n"
     ]
    }
   ],
   "source": [
    "topv = sorted(filter(lambda w: w[1] == \"quijote\", bigrams),\n",
    "                     key=lambda w: bigrams[w])[:-5:-1]\n",
    "\n",
    "wfreq = 0\n",
    "count = 0\n",
    "for v in topv:\n",
    "    if v[0] == \"don\":\n",
    "        wfreq = bigrams[v]\n",
    "    count += bigrams[v]\n",
    "print(wfreq / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = []\n",
    "for ws in zip(tokens[0:-1], tokens[1:len(tokens)]):\n",
    "    element = (w0, w1)\n",
    "    elements.append(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n$-gram estar√≠a compuesto de los elementos\n",
    "$$\n",
    "    t_k, t_{k + 1}, t_{k+2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngrams(tokens, ngram=2):\n",
    "    ntokens = len(tokens)\n",
    "    groups = [\n",
    "        tokens[slice(i, ntokens - ngram + i )]\n",
    "    for i in range(ngram)]\n",
    "    grams = [ws for ws in zip(*groups)]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('en', 'un', 'lugar', 'de', 'la')\n",
      "('un', 'lugar', 'de', 'la', 'mancha')\n",
      "('lugar', 'de', 'la', 'mancha', 'de')\n",
      "('de', 'la', 'mancha', 'de', 'cuyo')\n",
      "('la', 'mancha', 'de', 'cuyo', 'nombre')\n"
     ]
    }
   ],
   "source": [
    "for ws in make_ngrams(tokens, ngram=5)[:5]:\n",
    "    print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('el', 'caballero', 'de', 'la', 'triste', 'figura'), 21),\n",
       " (('caballero', 'don', 'quijote', 'de', 'la', 'mancha'), 16),\n",
       " (('de', 'don', 'quijote', 'de', 'la', 'mancha'), 16),\n",
       " (('senor', 'don', 'quijote', 'de', 'la', 'mancha'), 16),\n",
       " (('la', 'sin', 'par', 'dulcinea', 'del', 'toboso'), 14),\n",
       " (('todos', 'los', 'dias', 'de', 'mi', 'vida'), 14),\n",
       " (('dijo', 'a', 'esta', 'sazon', 'don', 'quijote'), 13),\n",
       " (('don', 'quijote', 'de', 'la', 'mancha', 'que'), 12),\n",
       " (('don', 'quijote', 'de', 'la', 'mancha', 'y'), 11),\n",
       " (('en', 'todos', 'los', 'dias', 'de', 'mi'), 10)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g5 = Counter(make_ngrams(tokens, ngram=6))\n",
    "g5.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topv = sorted(filter(lambda w: w[0] == \"mi\" and w[1] == \"perro\", g5),\n",
    "                     key=lambda w: g5[w])[:-5:-1]\n",
    "for v in topv:\n",
    "    print(v, g5[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['muerta y medio comida de perros y picada de grajos ',\n",
       " 'entro el cura de la perroquia y tomando a los ',\n",
       " 'y desatinada en poder destos perros naturales enemigos nuestros maldita ',\n",
       " 'otros como hacen a los perros cuando en pendencia estan ',\n",
       " 'sucedio pues que entre los perros que descargo la carga ',\n",
       " 'guarda en efeto todos cuantos perros topaba aunque fuesen alanos ',\n",
       " 'el lugar sino ladridos de perros que atronaban los oidos ',\n",
       " 'le vea yo comido de perros que asi nos trae ',\n",
       " 'ciguenas el cristel de los perros el vomito y el ',\n",
       " 'de que color serian los perros que pariese a lo ',\n",
       " 'por el ladrido de los perros como por el son ',\n",
       " 'suyos cuando acosado de los perros y seguido de los ',\n",
       " 'su propio dinero dos famosos perros para guardar el ganado ']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"(?:[a-z]+\\s){1,5}perros?(?:[a-z]+\\s){1,5}\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('en', 'un', 'lugar', 'de', 'la', 'mancha', 'de', 'cuyo', 'nombre', 'no')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = make_ngrams(tokens, ngram=10)\n",
    "sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8127, 21133, 13116, ...,  5904, 14679, 14659],\n",
       "       [21133, 13116,  6023, ..., 14679, 14659, 17320],\n",
       "       [13116,  6023, 12349, ..., 14659, 17320,   461],\n",
       "       ...,\n",
       "       [22035, 20983, 22034, ..., 20498, 19427,  7773],\n",
       "       [20983, 22034, 11112, ..., 19427,  7773,  1265],\n",
       "       [22034, 11112,  6023, ...,  7773,  1265, 21227]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sorted(list(set(tokens)))\n",
    "vocab_size = len(words)\n",
    "word_ix = {w:i for i, w in enumerate(words)}\n",
    "sequences_int = [[word_ix[word] for word in seq] for seq in sequences]\n",
    "sequences_int = np.array(sequences_int)\n",
    "sequences_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376471, 10)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = sequences_int[:,:-1], sequences_int[:, -1:]\n",
    "\n",
    "X_train = to_categorical(X_train, num_classes=vocab_size)\n",
    "y_train = to_categorical(y_train, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 9, 22147)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               8899200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 22147)             2236847   \n",
      "=================================================================\n",
      "Total params: 11,136,047\n",
      "Trainable params: 11,136,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_input = Input(X_train.shape[1:])\n",
    "X = LSTM(100, activation=\"relu\", return_sequences=False)(X_input)\n",
    "X = Dense(vocab_size, activation=\"softmax\")(X)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"despues de haber vivido su primera aventura don quijote se sentia meror√≥ eo d√≠as esegude acorras no en todo en esas a lo hecho y en entandero el de si mierda prosiba\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
