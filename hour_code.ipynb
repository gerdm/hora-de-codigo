{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hora de Código: Enseñando a Aprender\n",
    "## El pipeline de data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos nos encomiendan la tarea de escribir una sequela para el Libro Don Quixote de la Mancha. Debido a nuestra poca experiencia en obras literarias, y la inifinitesimal probabilidad de que hayamos leído la obra en su totalidad.\n",
    "\n",
    "![DonQuijote](https://www.telesurtv.net/__export/1421342197589/sites/telesur/img/multimedia/2015/01/15/quijote.jpg_1718483347.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lograr el objetivo, será necesario dividir la tarea en tres partes\n",
    "\n",
    "* **Análisis**\n",
    "* **Modelación**\n",
    "* **Producción**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from unidecode import unidecode\n",
    "from collections import Counter, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis\n",
    "----\n",
    "## Primeros Pasos\n",
    "\n",
    "Con el fin de escribir una sequela, lo primero que realizaremos será entender la primera parte del libro.\n",
    "\n",
    "**¿De qué manera podemos obtener acceso a la obra?**  \n",
    "1. Transcribir el libro a nuestra computadora \n",
    "2. Buscar el libro en línea, copiarlo y pegarlo en algún lugar para tener acceso a este\n",
    "3. Acceder directamente al libro y no tener que copiar y pegar nada (👍)\n",
    "\n",
    "Para nuestra suerte, la página _[Project Gutemberg](http://www.gutenberg.org)_ ofrece libros gratuitos en línea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin necesidad de acceder explicitamente a la página, podemos guardar el libro _Don Quijote_ por Miguel de Cervantes Saavedra con las siguientes líneas de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.gutenberg.org/cache/epub/2000/pg2000.txt\"\n",
    "r = requests.get(url)\n",
    "# Dentro de esta variable guardamos el texto\n",
    "corpus = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el texto que acabamos de descargar cuenta con información adicional al libro, limpiamos los datos a fin de acotar los datos a analizar y simplificar el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En las siguientes dos líneas de código buscamos el inicio y el final del libro\n",
    "init_book = corpus.find(\"En un lugar de la Mancha\")\n",
    "end_book = corpus.find(\"End of Project Gutenberg's\")\n",
    "# Acotamos el libro\n",
    "text = corpus[init_book: end_book]\n",
    "# Removemos acentos y eliminamos salltos de línas\n",
    "text = unidecode(text.replace(\"\\r\\n\", \" \")).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en un lugar de la mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivia un hidalgo de los de lanza en astillero, adarga antigua, rocin flaco y galgo corredor. una olla de algo mas vaca que carnero, salpicon las mas noches, duelos y quebrantos los sabados, lantejas los viernes, algun palomino de anadidura los domingos, consumian las tres partes de su hacienda. el resto della concluian sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los dias'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los primeros 500 carácteres del libro\n",
    "text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis que haremos a continuación consiste en analizar de una manera delimitada la manera en la que Miguel de Cervantes escribió el libro. Para esto, consideraremos cada una de las palabras dentro del texto y las guardaremos dentro de un arreglo ordenado de elementos conocido como una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en',\n",
       " 'un',\n",
       " 'lugar',\n",
       " 'de',\n",
       " 'la',\n",
       " 'mancha,',\n",
       " 'de',\n",
       " 'cuyo',\n",
       " 'nombre',\n",
       " 'no',\n",
       " 'quiero',\n",
       " 'acordarme,']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text.split()\n",
    "tokens[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la información manipulada hasta el momento, sería una buena idea ver qué palabras son las que más se repiten dentro del texto.\n",
    "\n",
    "**¿Qué palabras esperaríamos que se repitieran un mayor número de veces?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos cada una de de las palabras dentro de la lista\n",
    "word_counter = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('que', 19813),\n",
       " ('de', 17969),\n",
       " ('y', 16289),\n",
       " ('la', 10199),\n",
       " ('a', 9641),\n",
       " ('el', 9086),\n",
       " ('en', 8019),\n",
       " ('no', 5706),\n",
       " ('se', 5002),\n",
       " ('los', 4688)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los 10 elemento que más se repiten\n",
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder al número de veces que se repite una palabra en específico de la siguiente manera:\n",
    "```python\n",
    "word_counter[\"palabra\"]\n",
    "```\n",
    "Dónde `\"palabra\"` es la palabra a buscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter[\"dulcinea\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuántas veces se repite la palabra `\"quijote\"`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuántas veces se repite la palabra `\"amigo\"`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando el resultado de `word_counter.most_common(10)`, vemos que las palabras que más se repiten son redundantes para hacer un análisis del texto.\n",
    "\n",
    "Dentro del archivo `\"spanish_stop.pkl\"` guardamos una lista con palabras redundantes en español. Corre la siguiente celda. **¿Qué observas?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stopwords = pickle.load(open(\"spanish_stop.pkl\", \"rb\"))\n",
    "spanish_stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda filtrará los elementos que se encuentren dentro de la variable `spanish_stopwords`. **¿Qué palabras crees se repetirán más bajo este contexto?**\n",
    "\n",
    "Corre la siguiente celda para averiguar las 10 palabras que más se repiten, filtrando todas aquellas palabras que se encuentren deentro de la lista `spanish_stopwords`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = [t for t in tokens if t not in spanish_stopwords]\n",
    "clean_counter = Counter(clean_tokens)\n",
    "clean_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hagamos una imágen con las palabras que más se repiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "wordcloud = WordCloud().generate(\" \".join(clean_tokens))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los $n$-grams\n",
    "Saber las palabras que más se repiten no ofrece mucho contexto sobre la trama del libro. A fin de obtener un poco más de contexto sobre el libro contaremos _pares_ ordenados de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El siguiente código llena la lista \"elements\" con pares de\n",
    "# palabras dentro del libro\n",
    "elements = []\n",
    "for w0, w1 in zip(tokens[0:-1], tokens[1:len(tokens)]):\n",
    "    element = (w0, w1)\n",
    "    elements.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('en', 'un'),\n",
       " ('un', 'lugar'),\n",
       " ('lugar', 'de'),\n",
       " ('de', 'la'),\n",
       " ('la', 'mancha,')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al correr la siguiente celda, nos mostrará los pares de palabras con más repeticiones dentro del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = Counter(elements)\n",
    "bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora tenemos lo _bigram_ más comúnes, ¿de qué manera podemos conocer los _bigrams_ que empiecen con ciertas palabras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('don', 'quijote') 2149\n",
      "('don', 'fernando') 131\n",
      "('don', 'antonio') 62\n",
      "('don', 'luis') 36\n"
     ]
    }
   ],
   "source": [
    "topv = sorted(filter(lambda w: w[0] == \"don\", bigrams),\n",
    "                     key=lambda w: bigrams[w])[:-5:-1]\n",
    "for v in topv:\n",
    "    print(v, bigrams[v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿De qué manera podríamos calcular la probabilidad de que Cervantes haya escrito `\"quijote\"` dado que la palabra precedente a esta es `\"don\"`?\n",
    "\n",
    "$$\n",
    "    \\mathbb{P}(\\texttt{\"quijote\"} | \\texttt{\"don\"})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981421272642824\n"
     ]
    }
   ],
   "source": [
    "topv = sorted(filter(lambda w: w[1] == \"quijote\", bigrams),\n",
    "                     key=lambda w: bigrams[w])\n",
    "\n",
    "wfreq = 0\n",
    "count = 0\n",
    "for v in topv:\n",
    "    if v[0] == \"don\":\n",
    "        wfreq = bigrams[v]\n",
    "    count += bigrams[v]\n",
    "print(wfreq / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = []\n",
    "for ws in zip(tokens[0:-1], tokens[1:len(tokens)]):\n",
    "    element = (w0, w1)\n",
    "    elements.append(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dichos pares ordenados de palabras dentro de un texto se conocen como _bigrams_. En caso de tener tercias de palabras, estos se conocen como _trigrams_.\n",
    "\n",
    "En general,  $n$ palabras ordenadas dentro un texto se conocen como $n$-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalización\n",
    "Al igual que con las matemáticas, la generalización de un problema es de suma importancia. En el caso de la programación, podemos generalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngrams(tokens, ngram=2):\n",
    "    ntokens = len(tokens)\n",
    "    groups = [\n",
    "        tokens[slice(i, ntokens - ngram + i )]\n",
    "    for i in range(ngram)]\n",
    "    grams = [ws for ws in zip(*groups)]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('en', 'un', 'lugar', 'de', 'la')\n",
      "('un', 'lugar', 'de', 'la', 'mancha')\n",
      "('lugar', 'de', 'la', 'mancha', 'de')\n",
      "('de', 'la', 'mancha', 'de', 'cuyo')\n",
      "('la', 'mancha', 'de', 'cuyo', 'nombre')\n"
     ]
    }
   ],
   "source": [
    "for ws in make_ngrams(tokens, ngram=5)[:5]:\n",
    "    print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('el', 'caballero', 'de', 'la', 'triste', 'figura'), 21),\n",
       " (('caballero', 'don', 'quijote', 'de', 'la', 'mancha'), 16),\n",
       " (('de', 'don', 'quijote', 'de', 'la', 'mancha'), 16),\n",
       " (('senor', 'don', 'quijote', 'de', 'la', 'mancha'), 16),\n",
       " (('la', 'sin', 'par', 'dulcinea', 'del', 'toboso'), 14),\n",
       " (('todos', 'los', 'dias', 'de', 'mi', 'vida'), 14),\n",
       " (('dijo', 'a', 'esta', 'sazon', 'don', 'quijote'), 13),\n",
       " (('don', 'quijote', 'de', 'la', 'mancha', 'que'), 12),\n",
       " (('don', 'quijote', 'de', 'la', 'mancha', 'y'), 11),\n",
       " (('en', 'todos', 'los', 'dias', 'de', 'mi'), 10)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g5 = Counter(make_ngrams(tokens, ngram=6))\n",
    "g5.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topv = sorted(filter(lambda w: w[0] == \"mi\" and w[1] == \"perro\", g5),\n",
    "                     key=lambda w: g5[w])[:-5:-1]\n",
    "for v in topv:\n",
    "    print(v, g5[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['muerta y medio comida de perros y picada de grajos ',\n",
       " 'entro el cura de la perroquia y tomando a los ',\n",
       " 'y desatinada en poder destos perros naturales enemigos nuestros maldita ',\n",
       " 'otros como hacen a los perros cuando en pendencia estan ',\n",
       " 'sucedio pues que entre los perros que descargo la carga ',\n",
       " 'guarda en efeto todos cuantos perros topaba aunque fuesen alanos ',\n",
       " 'el lugar sino ladridos de perros que atronaban los oidos ',\n",
       " 'le vea yo comido de perros que asi nos trae ',\n",
       " 'ciguenas el cristel de los perros el vomito y el ',\n",
       " 'de que color serian los perros que pariese a lo ',\n",
       " 'por el ladrido de los perros como por el son ',\n",
       " 'suyos cuando acosado de los perros y seguido de los ',\n",
       " 'su propio dinero dos famosos perros para guardar el ganado ']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"(?:[a-z]+\\s){1,5}perros?(?:[a-z]+\\s){1,5}\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('en', 'un', 'lugar', 'de', 'la', 'mancha', 'de', 'cuyo', 'nombre', 'no')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = make_ngrams(tokens, ngram=10)\n",
    "sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8127, 21133, 13116, ...,  5904, 14679, 14659],\n",
       "       [21133, 13116,  6023, ..., 14679, 14659, 17320],\n",
       "       [13116,  6023, 12349, ..., 14659, 17320,   461],\n",
       "       ...,\n",
       "       [22035, 20983, 22034, ..., 20498, 19427,  7773],\n",
       "       [20983, 22034, 11112, ..., 19427,  7773,  1265],\n",
       "       [22034, 11112,  6023, ...,  7773,  1265, 21227]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sorted(list(set(tokens)))\n",
    "vocab_size = len(words)\n",
    "word_ix = {w:i for i, w in enumerate(words)}\n",
    "sequences_int = [[word_ix[word] for word in seq] for seq in sequences]\n",
    "sequences_int = np.array(sequences_int)\n",
    "sequences_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376471, 10)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = sequences_int[:,:-1], sequences_int[:, -1:]\n",
    "\n",
    "X_train = to_categorical(X_train, num_classes=vocab_size)\n",
    "y_train = to_categorical(y_train, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 9, 22147)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               8899200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 22147)             2236847   \n",
      "=================================================================\n",
      "Total params: 11,136,047\n",
      "Trainable params: 11,136,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_input = Input(X_train.shape[1:])\n",
    "X = LSTM(100, activation=\"relu\", return_sequences=False)(X_input)\n",
    "X = Dense(vocab_size, activation=\"softmax\")(X)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> despues de haber vivido su primera aventura don quijote se sentia meroró eo días esegude acorras no en todo en esas a lo hecho y en entandero el de si mierda prosiba\n",
    "\n",
    "> despues de haber vivido su primera aventura don quijote se sential a vaneras dalarr a trandarle de de veno caballero alguna fálque en contore que nocer estandoro pue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
