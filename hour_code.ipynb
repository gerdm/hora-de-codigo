{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hora de Código: Enseñando a Aprender\n",
    "## El pipeline de data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos nos encomiendan la tarea de escribir una sequela para el Libro Don Quixote de la Mancha. Debido a nuestra poca experiencia en obras literarias, y la inifinitesimal probabilidad de que hayamos leído la obra en su totalidad.\n",
    "\n",
    "![DonQuijote](https://www.telesurtv.net/__export/1421342197589/sites/telesur/img/multimedia/2015/01/15/quijote.jpg_1718483347.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lograr el objetivo, será necesario dividir la tarea en dos partes\n",
    "\n",
    "* **Análisis**\n",
    "* **Modelación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from unidecode import unidecode\n",
    "from collections import Counter, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis\n",
    "----\n",
    "## Primeros Pasos\n",
    "\n",
    "Con el fin de escribir una sequela, lo primero que realizaremos será entender la primera parte del libro.\n",
    "\n",
    "**¿De qué manera podemos obtener acceso a la obra?**  \n",
    "1. Transcribir el libro a nuestra computadora \n",
    "2. Buscar el libro en línea, copiarlo y pegarlo en algún lugar para tener acceso a este\n",
    "3. Acceder directamente al libro y no tener que copiar y pegar nada (👍)\n",
    "\n",
    "Para nuestra suerte, la página _[Project Gutemberg](http://www.gutenberg.org)_ ofrece libros gratuitos en línea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin necesidad de acceder explicitamente a la página, podemos guardar el libro _Don Quijote_ por Miguel de Cervantes Saavedra con las siguientes líneas de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.gutenberg.org/cache/epub/2000/pg2000.txt\"\n",
    "r = requests.get(url)\n",
    "# Dentro de esta variable guardamos el texto\n",
    "corpus = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el texto que acabamos de descargar cuenta con información adicional al libro, limpiamos los datos a fin de acotar los datos a analizar y simplificar el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En las siguientes dos líneas de código buscamos el inicio y el final del libro\n",
    "init_book = corpus.find(\"En un lugar de la Mancha\")\n",
    "end_book = corpus.find(\"End of Project Gutenberg's\")\n",
    "# Acotamos el libro\n",
    "text = corpus[init_book: end_book]\n",
    "# Removemos acentos y eliminamos salltos de línas\n",
    "text = unidecode(text.replace(\"\\r\\n\", \" \")).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en un lugar de la mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivia un hidalgo de los de lanza en astillero, adarga antigua, rocin flaco y galgo corredor. una olla de algo mas vaca que carnero, salpicon las mas noches, duelos y quebrantos los sabados, lantejas los viernes, algun palomino de anadidura los domingos, consumian las tres partes de su hacienda. el resto della concluian sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los dias'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los primeros 500 carácteres del libro\n",
    "text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis que haremos a continuación consiste en analizar de una manera delimitada la manera en la que Miguel de Cervantes escribió el libro. Para esto, consideraremos cada una de las palabras dentro del texto y las guardaremos dentro de un arreglo ordenado de elementos conocido como una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en',\n",
       " 'un',\n",
       " 'lugar',\n",
       " 'de',\n",
       " 'la',\n",
       " 'mancha,',\n",
       " 'de',\n",
       " 'cuyo',\n",
       " 'nombre',\n",
       " 'no',\n",
       " 'quiero',\n",
       " 'acordarme,']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text.split()\n",
    "tokens[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la información manipulada hasta el momento, sería una buena idea ver qué palabras son las que más se repiten dentro del texto.\n",
    "\n",
    "**¿Qué palabras esperaríamos que se repitieran un mayor número de veces?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos cada una de de las palabras dentro de la lista\n",
    "word_counter = Counter(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corre la siguiente celda para observar las palabras que más se repiten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos los 10 elemento que más se repiten\n",
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder al número de veces que se repite una palabra en específico de la siguiente manera:\n",
    "```python\n",
    "word_counter[\"palabra\"]\n",
    "```\n",
    "Dónde `\"palabra\"` es la palabra a buscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter[\"dulcinea\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuántas veces se repite la palabra `\"quijote\"`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuántas veces se repite la palabra `\"amigo\"`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando el resultado de `word_counter.most_common(10)`, vemos que las palabras que más se repiten son redundantes para hacer un análisis del texto.\n",
    "\n",
    "Dentro del archivo `\"spanish_stop.pkl\"` guardamos una lista con palabras redundantes en español. Corre la siguiente celda. **¿Qué observas?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stopwords = pickle.load(open(\"./files/spanish_stop.pkl\", \"rb\"))\n",
    "spanish_stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda filtrará los elementos que se encuentren dentro de la variable `spanish_stopwords`. **¿Qué palabras crees se repetirán más bajo este contexto?**\n",
    "\n",
    "Corre la siguiente celda para averiguar las 10 palabras que más se repiten, filtrando todas aquellas palabras que se encuentren deentro de la lista `spanish_stopwords`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = [t for t in tokens if t not in spanish_stopwords]\n",
    "clean_counter = Counter(clean_tokens)\n",
    "clean_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hagamos una imágen con las palabras que más se repiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "wordcloud = WordCloud().generate(\" \".join(clean_tokens))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los $n$-grams\n",
    "Saber las palabras que más se repiten no ofrece mucho contexto sobre la trama del libro. A fin de obtener un poco más de contexto sobre el libro contaremos _pares_ ordenados de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El siguiente código llena la lista \"elements\" con pares de\n",
    "# palabras dentro del libro\n",
    "elements = []\n",
    "for w0, w1 in zip(tokens[0:-1], tokens[1:len(tokens)]):\n",
    "    element = (w0, w1)\n",
    "    elements.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('en', 'un'),\n",
       " ('un', 'lugar'),\n",
       " ('lugar', 'de'),\n",
       " ('de', 'la'),\n",
       " ('la', 'mancha,')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al correr la siguiente celda, nos mostrará los pares de palabras con más repeticiones dentro del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = Counter(elements)\n",
    "bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora tenemos lo _bigram_ más comúnes, **¿de qué manera podemos conocer los _bigrams_ que empiecen con ciertas palabras?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topv = sorted(filter(lambda w: w[0] == \"don\", bigrams),\n",
    "                     key=lambda w: bigrams[w])[:-5:-1]\n",
    "for v in topv:\n",
    "    print(v, bigrams[v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿De qué manera podríamos calcular la probabilidad de que Cervantes haya escrito `\"quijote\"` dado que la palabra precedente a esta es `\"don\"`?\n",
    "\n",
    "$$\n",
    "    \\mathbb{P}(\\texttt{\"quijote\"} | \\texttt{\"don\"})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981421272642824\n"
     ]
    }
   ],
   "source": [
    "topv = sorted(filter(lambda w: w[1] == \"quijote\", bigrams),\n",
    "                     key=lambda w: bigrams[w])\n",
    "\n",
    "wfreq = 0\n",
    "count = 0\n",
    "for v in topv:\n",
    "    if v[0] == \"don\":\n",
    "        wfreq = bigrams[v]\n",
    "    count += bigrams[v]\n",
    "print(wfreq / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dichos pares ordenados de palabras dentro de un texto se conocen como _bigrams_. En caso de tener tercias de palabras, estos se conocen como _trigrams_.\n",
    "\n",
    "En general,  $n$ palabras ordenadas dentro un texto se conocen como $n$-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalización\n",
    "Al igual que con las matemáticas, la generalización de un problema es de suma importancia. En el caso de la programación, una manera manera de generalizar un problema es mediante la creación de una función.\n",
    "\n",
    "Para el análisis que hemos estado realizando, nos gustaría definir una función que nos arroje los $n$-grams del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngrams(tokens, ngram=2):\n",
    "    ntokens = len(tokens)\n",
    "    groups = [\n",
    "        tokens[slice(i, ntokens - ngram + i )]\n",
    "    for i in range(ngram)]\n",
    "    grams = [ws for ws in zip(*groups)]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('en', 'un')\n",
      "('un', 'lugar')\n",
      "('lugar', 'de')\n",
      "('de', 'la')\n",
      "('la', 'mancha,')\n"
     ]
    }
   ],
   "source": [
    "for ws in make_ngrams(tokens, ngram=2)[:5]:\n",
    "    print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('don', 'quijote', 'de', 'la', 'mancha,'), 79),\n",
       " (('don', 'quijote', 'de', 'la', 'mancha'), 25),\n",
       " (('en', 'todos', 'los', 'dias', 'de'), 21),\n",
       " (('el', 'caballero', 'de', 'la', 'triste'), 21),\n",
       " (('caballero', 'don', 'quijote', 'de', 'la'), 17),\n",
       " (('de', 'don', 'quijote', 'de', 'la'), 16),\n",
       " (('senor', 'don', 'quijote', 'de', 'la'), 16),\n",
       " (('la', 'sin', 'par', 'dulcinea', 'del'), 14),\n",
       " (('todos', 'los', 'dias', 'de', 'mi'), 14),\n",
       " (('el', 'cura', 'y', 'el', 'barbero'), 13)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g5 = Counter(make_ngrams(tokens, ngram=5))\n",
    "g5.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('don', 'fernando', 'y', 'sus', 'camaradas,') 2\n",
      "('don', 'fernando', 'y', 'a', 'los') 2\n",
      "('don', 'fernando', 'de', 'guevara,', 'donde') 1\n",
      "('don', 'fernando', 'al', 'cura', 'donde') 1\n"
     ]
    }
   ],
   "source": [
    "topv = sorted(filter(lambda w: w[0] == \"don\" and w[1] == \"fernando\", g5),\n",
    "                     key=lambda w: g5[w])[:-5:-1]\n",
    "for v in topv:\n",
    "    print(v, g5[v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelando con $n$-grams \n",
    "\n",
    "Para modelar con $n$-grams, hacemos la siguiente suposición.\n",
    "$$\n",
    "    \\mathbb{P}(w_M | w_{M-1}, w_{M-2}, \\ldots, w_{1}) = \\mathbb{P}(w_M | w_{M-1}, w_{M-2}, \\ldots, w_{M -{N+1}})\n",
    "$$\n",
    "\n",
    "**¿Qué pasa cuando $n=2$?**\n",
    "\n",
    "\n",
    "* Al modelar nuestro sistema con $n$-grams es necesario guardar y calcular, a cada iteración, la probabilidad de las palabras\n",
    "* ¿Qué sucede si no existe probabilidad conocida?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(tokens, counter):\n",
    "    \"\"\"\n",
    "    For a list tokens of size n (len(tokens) == n),\n",
    "    estimate all next n+1 words following tokens. If there are\n",
    "    none, return an empty list\n",
    "    \"\"\"\n",
    "    probs = []\n",
    "    elements = []\n",
    "    for v in counter:\n",
    "        if \" \".join(tokens) == \" \".join(v[:-1]):\n",
    "            elements.append(v[-1])\n",
    "            probs.append(counter[v])\n",
    "    return elements, np.array(probs) / sum(probs)\n",
    "\n",
    "def next_word(seed_tokens, tokens_corpus):\n",
    "    \"\"\"\n",
    "    Estimate next word based on the \"seed_tokens\". If\n",
    "    there is no len(seed_tokens) + 1 ngram that matches the\n",
    "    seed tokens, reduce the token one element up until you\n",
    "    simply estimate a random word\n",
    "    \"\"\"\n",
    "    skip = 0\n",
    "    empty = True\n",
    "    n = len(seed_tokens) + 1\n",
    "    while empty:\n",
    "        grams = make_ngrams(tokens_corpus, ngram=n)\n",
    "        gram_counter = Counter(grams)\n",
    "        e, p = filter_tokens(seed_tokens[skip:], gram_counter)\n",
    "        if len(e) > 0:\n",
    "            empty = False\n",
    "        else:\n",
    "            skip += 1\n",
    "            n -= 1\n",
    "    word = choice(e, p=p)\n",
    "    return word\n",
    "\n",
    "def write(seed_str, corpus_tokens, nwords=15, verbose=False):\n",
    "    seed_tokens = seed_str.split()\n",
    "    for _ in range(nwords):\n",
    "        word = next_word(seed_tokens, corpus_tokens)\n",
    "        seed_tokens.append(word)\n",
    "        if verbose:\n",
    "            print(\" \".join(seed_tokens))\n",
    "    return \" \".join(seed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corre la siguiente celda para empezar a escribir nuestra nueva versión del libro usando _n-grams_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1643)\n",
    "write(\"en un lugar\", tokens, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior, nuestro cuento empieza con `\"en un lugar\"`. Modifica la siguiente celda para crear un inicio alternativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"\", tokens, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Las desventajas de un modelo $n$-gram\n",
    "* A medida que nuestro cuento crece, el tiempo de respuesta incrrementa\n",
    "* Es necesario tener toda la información a todo momento para poder hacer uso de esta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelando con LSTMs\n",
    "\n",
    "Una manera alternativa de escribir nuestro libro es _entrenar_ un modelo de redes neuronales que, de alguna manera, entienda semántica y estructura de la escritura.\n",
    "\n",
    "En terminología de machine learrning, decimos que _entrenamos_ un modelo paramétrico cuando hacemos cualquier proceso a fin de llegar a los pesos $\\theta$ del modelo que minimicen cierto error $\\mathcal L$.\n",
    "\n",
    "La arquitectura de redes neuronales que necesitamos para solucionar este problema es conocida como RNN (Recurrent Neural Network). Específicamente, ocuparemos un _estilo_ del celda conocido como LSTM (Long-Short Term Memory) que nos ayude a escribir nuestro libro\n",
    "\n",
    "![LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n",
    "\n",
    "Los siguientes dos links son una buena introducción hacía el poder de los RNNs\n",
    "* https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "**Nota**: Es necesario tener la librería _TensorFlow_ instalada para poder correr la siguiente parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;31m\u001b[Ktensorflow\u001b[m\u001b[K==1.12.0\r\n",
      "\u001b[01;31m\u001b[Ktensorflow\u001b[m\u001b[K-tensorboard==1.5.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un modelo con un LSTM requiere de miles de parámetros y cientos de iteraciones para converger. Sin embargo, la ventaja de entrenar un LSTM es la flexibilidad que nos da para entrenar el modelo.\n",
    "\n",
    "Para este ejmplo, en lugar de entrenar el modelo palabra por palabra, lo haremos caractér por caractér.\n",
    "\n",
    "* **¿Qué ventajas tendrá entrenar un modelo de esta manera?** \n",
    "* **¿Qué desventajas tendrá entrenar un modelo de esta manera?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este nueva variante del modelo, en lugar de necesitar palabras iniciales, el modelo necesitará un número específico de carácteres iniciales. En nuestro caso 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenght = 60\n",
    "sequences = [text[ix-lenght: ix+1] for ix in range(lenght, len(text))]\n",
    "ch_ix = pickle.load(open(\"./files/encoding_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fin de tener una manera numérica de manipular la información, codificaremos cada caractér por un valor único otorgado por nuestro programa.\n",
    "\n",
    "Asumiendo que el cuento tiene $S$ sequencias y $E$ carácteres por sequencia, transformaremos nuestros datos a fin de tener una matriz $S\\times E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en un lugar de la mancha, de cuyo nombre no quiero acordarme,',\n",
       " 'n un lugar de la mancha, de cuyo nombre no quiero acordarme, ',\n",
       " ' un lugar de la mancha, de cuyo nombre no quiero acordarme, n',\n",
       " 'un lugar de la mancha, de cuyo nombre no quiero acordarme, no',\n",
       " 'n lugar de la mancha, de cuyo nombre no quiero acordarme, no ',\n",
       " ' lugar de la mancha, de cuyo nombre no quiero acordarme, no h',\n",
       " 'lugar de la mancha, de cuyo nombre no quiero acordarme, no ha',\n",
       " 'ugar de la mancha, de cuyo nombre no quiero acordarme, no ha ',\n",
       " 'gar de la mancha, de cuyo nombre no quiero acordarme, no ha m',\n",
       " 'ar de la mancha, de cuyo nombre no quiero acordarme, no ha mu']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2071389"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 35,  0, ..., 34, 27,  6],\n",
       "       [35,  0, 42, ..., 27,  6,  0],\n",
       "       [ 0, 42, 35, ...,  6,  0, 35],\n",
       "       ...,\n",
       "       [46,  0, 30, ...,  0,  0,  0],\n",
       "       [ 0, 30, 23, ...,  0,  0,  0],\n",
       "       [30, 23, 35, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "sequences_int = [[ch_ix[ch] for ch in seq] for seq in sequences]\n",
    "sequences_int = np.array(sequences_int)\n",
    "sequences_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2071389, 61)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_int.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendiendo a Escribir\n",
    "\n",
    "Finalmente, para enseñarle a nuestro modelo a escribir, modelamos nuestro problema de la siguiente manera: dado $n-1$ carácteres, queremos que el modelo estime el $n$-ésimo carácter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de una red neuronal, así como en varios problemas en machine learning, la codificación categorica de un valor a un entero puede ocasionar resultados subóptimos al momento de entrenar el modelo. Para evitar esto, transformaremos cada carácter a un vector de dimensión $C$ (siendo $C$ el número de carácteres únicos), en el cuál todos los elementos de este nuevo vector son 0, excepto por la posición\n",
    "\n",
    "Por ejemplo, si un caractér tiene valor $2$, creamos un vector $[0, 0, 1, \\ldots, 0]$; de igual manera si un carácter tiene valor $0$, creamos un vector de la forma $[1, 0, 0, \\ldots, 0]$. Y así sucesivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = sequences_int[:50,:-1], sequences_int[:50, -1:]\n",
    "\n",
    "X_train = to_categorical(X_train, num_classes=vocab_size)\n",
    "y_train = to_categorical(y_train, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo estas dos consideraciones, obtenemos una matriz $S\\times C$ de carácteres por estimar y un arreglo 3-dimensional $S\\times E \\times C$ de datos dependientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 48)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 60, 48)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definimos una pequeña arquitectura de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 48)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               59600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 48)                4848      \n",
      "=================================================================\n",
      "Total params: 64,448\n",
      "Trainable params: 64,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_input = Input(X_train.shape[1:])\n",
    "X = LSTM(100, activation=\"relu\", return_sequences=False)(X_input)\n",
    "X = Dense(vocab_size, activation=\"softmax\")(X)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 3.8622 - acc: 0.0200\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.8604 - acc: 0.0200\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.8587 - acc: 0.0200\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.8568 - acc: 0.0200\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.8551 - acc: 0.0200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x126024208>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado el modelo, podemos hacer inferencia sobre nuestro nuevo libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer(seed_txt, model, encoding, nchars=100):\n",
    "    seq = (seed_txt)\n",
    "    decoding = {val:char for char, val in encoding.items()}\n",
    "    n_chars = len(encoding)\n",
    "    seq = \"despues de haber vivido su primera aventura don quijote se sentia\"\n",
    "    text_seq = deque([ch for ch in seq], maxlen=lenght)\n",
    "\n",
    "    for _ in range(nchars):\n",
    "        encoded = [encoding[ch] for ch in text_seq]\n",
    "        encoded = pad_sequences([encoded], maxlen=lenght, padding=\"pre\")\n",
    "        encoded = to_categorical(encoded, num_classes=n_chars).reshape(1, -1, n_chars)\n",
    "        probs = model.predict(encoded, batch_size=1)\n",
    "        pred = np.random.choice(np.arange(n_chars), p=probs.ravel())\n",
    "        char = decoding[pred]\n",
    "        text_seq.append(char)\n",
    "        seq += char\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'despues de haber vivido su primera aventura don quijote se sentia,v, -h)du3(5evw \"wbapnf)-;h2hl?xj1r)vtux4;x,sv.0].6v7h;f:>z1).]q0p-ul-a);(5ob)gij37p:z5h:d3\")vodf,;i'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"despues de haber vivido su primera aventura don quijote se sentia\"\n",
    "writer(txt, model, ch_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer nuestro modelo no es tan bueno para escribir un libro..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto último se debe a que necesitamos varias épocas de entrenamiento para llegar un mejor modelo que pueda escribir un libro. Los siguientes ejemplos muestran la vida del modelo después de varias épocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ~ 5 epochs (5 secuencias):  \n",
    "`despues de haber vivido su primera aventura don quijote se sentia??yv2u'.)roes10v]h(0tn3aho-?uz ;>\"7du-az4-yinj6xs(6 :n?ma,;]gg;'s'4)w0em\" ?hu'stsg1i'goy!e\"(>wsb,uz4`\n",
    "\n",
    "* ~ 50 epochs:   \n",
    "  `despues de haber vivido su primera aventura don quijote se sentias eldeno- uelvimes o`\n",
    "  \n",
    "* ~ 150 epochs:   \n",
    "  `despues de haber vivido su primera aventura don quijote se sentia serentas tan ojo es busa coma estado este amanas. ahardada digustra mando, con somparia de egla fue``\n",
    "  \n",
    "* ~ 190 epochs:   \n",
    "  `despues de haber vivido su primera aventura don quijote se sentia de aris, dilino; ya a oflico el estria don quiso y nuesa.  y si no tenda trezas que tienele y de lg`\n",
    "\n",
    "* ~ 350\n",
    "epochs:   \n",
    "`despues de haber vivido su primera aventura don quijote se sentia y todos y don principas respiedo; y he vivo las mojos villos de diabroso, dijo y conoto cual cococi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimando sobre un modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"files/charmodelv04_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1643)\n",
    "writer(txt, model, ch_ix, 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
