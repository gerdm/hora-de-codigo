{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hora de C√≥digo: Ense√±ando a Aprender\n",
    "## El pipeline de data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos nos encomiendan la tarea de escribir una sequela para el Libro Don Quixote de la Mancha. Debido a nuestra poca experiencia en obras literarias, y la inifinitesimal probabilidad de que hayamos le√≠do la obra en su totalidad.\n",
    "\n",
    "![DonQuijote](https://www.telesurtv.net/__export/1421342197589/sites/telesur/img/multimedia/2015/01/15/quijote.jpg_1718483347.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lograr el objetivo, ser√° necesario dividir la tarea en tres partes\n",
    "\n",
    "* **An√°lisis**\n",
    "* **Modelaci√≥n**\n",
    "* **Producci√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from unidecode import unidecode\n",
    "from collections import Counter, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis\n",
    "----\n",
    "## Primeros Pasos\n",
    "\n",
    "Con el fin de escribir una sequela, lo primero que realizaremos ser√° entender la primera parte del libro.\n",
    "\n",
    "**¬øDe qu√© manera podemos obtener acceso a la obra?**  \n",
    "1. Transcribir el libro a nuestra computadora \n",
    "2. Buscar el libro en l√≠nea, copiarlo y pegarlo en alg√∫n lugar para tener acceso a este\n",
    "3. Acceder directamente al libro y no tener que copiar y pegar nada (üëç)\n",
    "\n",
    "Para nuestra suerte, la p√°gina _[Project Gutemberg](http://www.gutenberg.org)_ ofrece libros gratuitos en l√≠nea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin necesidad de acceder explicitamente a la p√°gina, podemos guardar el libro _Don Quijote_ por Miguel de Cervantes Saavedra con las siguientes l√≠neas de c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.gutenberg.org/cache/epub/2000/pg2000.txt\"\n",
    "r = requests.get(url)\n",
    "# Dentro de esta variable guardamos el texto\n",
    "corpus = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el texto que acabamos de descargar cuenta con informaci√≥n adicional al libro, limpiamos los datos a fin de acotar los datos a analizar y simplificar el an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En las siguientes dos l√≠neas de c√≥digo buscamos el inicio y el final del libro\n",
    "init_book = corpus.find(\"En un lugar de la Mancha\")\n",
    "end_book = corpus.find(\"End of Project Gutenberg's\")\n",
    "# Acotamos el libro\n",
    "text = corpus[init_book: end_book]\n",
    "# Removemos acentos y eliminamos salltos de l√≠nas\n",
    "text = unidecode(text.replace(\"\\r\\n\", \" \")).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en un lugar de la mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivia un hidalgo de los de lanza en astillero, adarga antigua, rocin flaco y galgo corredor. una olla de algo mas vaca que carnero, salpicon las mas noches, duelos y quebrantos los sabados, lantejas los viernes, algun palomino de anadidura los domingos, consumian las tres partes de su hacienda. el resto della concluian sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los dias'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los primeros 500 car√°cteres del libro\n",
    "text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El an√°lisis que haremos a continuaci√≥n consiste en analizar de una manera delimitada la manera en la que Miguel de Cervantes escribi√≥ el libro. Para esto, consideraremos cada una de las palabras dentro del texto y las guardaremos dentro de un arreglo ordenado de elementos conocido como una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en',\n",
       " 'un',\n",
       " 'lugar',\n",
       " 'de',\n",
       " 'la',\n",
       " 'mancha,',\n",
       " 'de',\n",
       " 'cuyo',\n",
       " 'nombre',\n",
       " 'no',\n",
       " 'quiero',\n",
       " 'acordarme,']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text.split()\n",
    "tokens[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la informaci√≥n manipulada hasta el momento, ser√≠a una buena idea ver qu√© palabras son las que m√°s se repiten dentro del texto.\n",
    "\n",
    "**¬øQu√© palabras esperar√≠amos que se repitieran un mayor n√∫mero de veces?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos cada una de de las palabras dentro de la lista\n",
    "word_counter = Counter(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corre la siguiente celda para observar las palabras que m√°s se repiten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos los 10 elemento que m√°s se repiten\n",
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder al n√∫mero de veces que se repite una palabra en espec√≠fico de la siguiente manera:\n",
    "```python\n",
    "word_counter[\"palabra\"]\n",
    "```\n",
    "D√≥nde `\"palabra\"` es la palabra a buscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter[\"dulcinea\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¬øCu√°ntas veces se repite la palabra `\"quijote\"`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¬øCu√°ntas veces se repite la palabra `\"amigo\"`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando el resultado de `word_counter.most_common(10)`, vemos que las palabras que m√°s se repiten son redundantes para hacer un an√°lisis del texto.\n",
    "\n",
    "Dentro del archivo `\"spanish_stop.pkl\"` guardamos una lista con palabras redundantes en espa√±ol. Corre la siguiente celda. **¬øQu√© observas?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stopwords = pickle.load(open(\"spanish_stop.pkl\", \"rb\"))\n",
    "spanish_stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda filtrar√° los elementos que se encuentren dentro de la variable `spanish_stopwords`. **¬øQu√© palabras crees se repetir√°n m√°s bajo este contexto?**\n",
    "\n",
    "Corre la siguiente celda para averiguar las 10 palabras que m√°s se repiten, filtrando todas aquellas palabras que se encuentren deentro de la lista `spanish_stopwords`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = [t for t in tokens if t not in spanish_stopwords]\n",
    "clean_counter = Counter(clean_tokens)\n",
    "clean_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hagamos una im√°gen con las palabras que m√°s se repiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "wordcloud = WordCloud().generate(\" \".join(clean_tokens))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los $n$-grams\n",
    "Saber las palabras que m√°s se repiten no ofrece mucho contexto sobre la trama del libro. A fin de obtener un poco m√°s de contexto sobre el libro contaremos _pares_ ordenados de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El siguiente c√≥digo llena la lista \"elements\" con pares de\n",
    "# palabras dentro del libro\n",
    "elements = []\n",
    "for w0, w1 in zip(tokens[0:-1], tokens[1:len(tokens)]):\n",
    "    element = (w0, w1)\n",
    "    elements.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('en', 'un'),\n",
       " ('un', 'lugar'),\n",
       " ('lugar', 'de'),\n",
       " ('de', 'la'),\n",
       " ('la', 'mancha,')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al correr la siguiente celda, nos mostrar√° los pares de palabras con m√°s repeticiones dentro del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = Counter(elements)\n",
    "bigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora tenemos lo _bigram_ m√°s com√∫nes, **¬øde qu√© manera podemos conocer los _bigrams_ que empiecen con ciertas palabras?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topv = sorted(filter(lambda w: w[0] == \"don\", bigrams),\n",
    "                     key=lambda w: bigrams[w])[:-5:-1]\n",
    "for v in topv:\n",
    "    print(v, bigrams[v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øDe qu√© manera podr√≠amos calcular la probabilidad de que Cervantes haya escrito `\"quijote\"` dado que la palabra precedente a esta es `\"don\"`?\n",
    "\n",
    "$$\n",
    "    \\mathbb{P}(\\texttt{\"quijote\"} | \\texttt{\"don\"})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981421272642824\n"
     ]
    }
   ],
   "source": [
    "topv = sorted(filter(lambda w: w[1] == \"quijote\", bigrams),\n",
    "                     key=lambda w: bigrams[w])\n",
    "\n",
    "wfreq = 0\n",
    "count = 0\n",
    "for v in topv:\n",
    "    if v[0] == \"don\":\n",
    "        wfreq = bigrams[v]\n",
    "    count += bigrams[v]\n",
    "print(wfreq / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dichos pares ordenados de palabras dentro de un texto se conocen como _bigrams_. En caso de tener tercias de palabras, estos se conocen como _trigrams_.\n",
    "\n",
    "En general,  $n$ palabras ordenadas dentro un texto se conocen como $n$-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalizaci√≥n\n",
    "Al igual que con las matem√°ticas, la generalizaci√≥n de un problema es de suma importancia. En el caso de la programaci√≥n, una manera manera de generalizar un problema es mediante la creaci√≥n de una funci√≥n.\n",
    "\n",
    "Para el an√°lisis que hemos estado realizando, nos gustar√≠a definir una funci√≥n que nos arroje los $n$-grams del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngrams(tokens, ngram=2):\n",
    "    ntokens = len(tokens)\n",
    "    groups = [\n",
    "        tokens[slice(i, ntokens - ngram + i )]\n",
    "    for i in range(ngram)]\n",
    "    grams = [ws for ws in zip(*groups)]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('en', 'un')\n",
      "('un', 'lugar')\n",
      "('lugar', 'de')\n",
      "('de', 'la')\n",
      "('la', 'mancha,')\n"
     ]
    }
   ],
   "source": [
    "for ws in make_ngrams(tokens, ngram=2)[:5]:\n",
    "    print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('don', 'quijote', 'de', 'la', 'mancha,'), 79),\n",
       " (('don', 'quijote', 'de', 'la', 'mancha'), 25),\n",
       " (('en', 'todos', 'los', 'dias', 'de'), 21),\n",
       " (('el', 'caballero', 'de', 'la', 'triste'), 21),\n",
       " (('caballero', 'don', 'quijote', 'de', 'la'), 17),\n",
       " (('de', 'don', 'quijote', 'de', 'la'), 16),\n",
       " (('senor', 'don', 'quijote', 'de', 'la'), 16),\n",
       " (('la', 'sin', 'par', 'dulcinea', 'del'), 14),\n",
       " (('todos', 'los', 'dias', 'de', 'mi'), 14),\n",
       " (('el', 'cura', 'y', 'el', 'barbero'), 13)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g5 = Counter(make_ngrams(tokens, ngram=5))\n",
    "g5.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('don', 'fernando', 'y', 'sus', 'camaradas,') 2\n",
      "('don', 'fernando', 'y', 'a', 'los') 2\n",
      "('don', 'fernando', 'de', 'guevara,', 'donde') 1\n",
      "('don', 'fernando', 'al', 'cura', 'donde') 1\n"
     ]
    }
   ],
   "source": [
    "topv = sorted(filter(lambda w: w[0] == \"don\" and w[1] == \"fernando\", g5),\n",
    "                     key=lambda w: g5[w])[:-5:-1]\n",
    "for v in topv:\n",
    "    print(v, g5[v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelando con $n$-grams \n",
    "\n",
    "Para modelar con $n$-grams, hacemos la siguiente suposici√≥n.\n",
    "$$\n",
    "    \\mathbb{P}(w_M | w_{M-1}, w_{M-2}, \\ldots, w_{1}) = \\mathbb{P}(w_M | w_{M-1}, w_{M-2}, \\ldots, w_{M -{N+1}})\n",
    "$$\n",
    "\n",
    "**¬øQu√© pasa cuando $n=2$?**\n",
    "\n",
    "\n",
    "* Al modelar nuestro sistema con $n$-grams es necesario guardar y calcular, a cada iteraci√≥n, la probabilidad de las palabras\n",
    "* ¬øQu√© sucede si no existe probabilidad conocida?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(tokens, counter):\n",
    "    \"\"\"\n",
    "    For a list tokens of size n (len(tokens) == n),\n",
    "    estimate all next n+1 words following tokens. If there are\n",
    "    none, return an empty list\n",
    "    \"\"\"\n",
    "    probs = []\n",
    "    elements = []\n",
    "    for v in counter:\n",
    "        if \" \".join(tokens) == \" \".join(v[:-1]):\n",
    "            elements.append(v[-1])\n",
    "            probs.append(counter[v])\n",
    "    return elements, np.array(probs) / sum(probs)\n",
    "\n",
    "def next_word(seed_tokens, tokens_corpus):\n",
    "    \"\"\"\n",
    "    Estimate next word based on the \"seed_tokens\". If\n",
    "    there is no len(seed_tokens) + 1 ngram that matches the\n",
    "    seed tokens, reduce the token one element up until you\n",
    "    simply estimate a random word\n",
    "    \"\"\"\n",
    "    skip = 0\n",
    "    empty = True\n",
    "    n = len(seed_tokens) + 1\n",
    "    while empty:\n",
    "        grams = make_ngrams(tokens_corpus, ngram=n)\n",
    "        gram_counter = Counter(grams)\n",
    "        e, p = filter_tokens(seed_tokens[skip:], gram_counter)\n",
    "        if len(e) > 0:\n",
    "            empty = False\n",
    "        else:\n",
    "            skip += 1\n",
    "            n -= 1\n",
    "    word = choice(e, p=p)\n",
    "    return word\n",
    "\n",
    "def write(seed_str, corpus_tokens, nwords=15, verbose=False):\n",
    "    seed_tokens = seed_str.split()\n",
    "    for _ in range(nwords):\n",
    "        word = next_word(seed_tokens, corpus_tokens)\n",
    "        seed_tokens.append(word)\n",
    "        if verbose:\n",
    "            print(\" \".join(seed_tokens))\n",
    "    return \" \".join(seed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corre la siguiente celda para empezar a escribir nuestra nueva versi√≥n del libro usando _n-grams_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1643)\n",
    "write(\"en un lugar\", tokens, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior, nuestro cuento empieza con `\"en un lugar\"`. Modifica la siguiente celda para crear un inicio alternativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"**aqu√≠ va tu string**\", tokens, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Las desventajas de un modelo $n$-gram\n",
    "* A medida que nuestro cuento crece, el tiempo de respuesta incrrementa\n",
    "* Es necesario tener toda la informaci√≥n a todo momento para poder hacer uso de esta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelando con LSTMs\n",
    "\n",
    "Una manera alternativa de escribir nuestro libro es _entrenar_ un modelo de redes neuronales que, de alguna manera, entienda sem√°ntica y estructura de la escritura.\n",
    "\n",
    "En terminolog√≠a de machine learrning, decimos que _entrenamos_ un modelo param√©trico cuando hacemos cualquier proceso a fin de llegar a los pesos $\\theta$ del modelo que minimicen cierto error $\\mathcal L$.\n",
    "\n",
    "La arquitectura de redes neuronales que necesitamos para solucionar este problema es conocida como RNN (Recurrent Neural Network). Espec√≠ficamente, ocuparemos un _estilo_ del celda conocido como LSTM (Long-Short Term Memory) que nos ayude a escribir nuestro libro\n",
    "\n",
    "![LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n",
    "\n",
    "Los siguientes dos links son una buena introducci√≥n hac√≠a el poder de los RNNs\n",
    "* https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un modelo con un LSTM requiere de miles de par√°metros y cientos de iteraciones para converger. Sin embargo, la ventaja de entrenar un LSTM es la flexibilidad que nos da para entrenar el modelo.\n",
    "\n",
    "Para este ejmplo, en lugar de entrenar el modelo palabra por palabra, lo haremos caract√©r por caract√©r.\n",
    "\n",
    "* **¬øQu√© ventajas tendr√° entrenar un modelo de esta manera?** \n",
    "* **¬øQu√© desventajas tendr√° entrenar un modelo de esta manera?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este nueva variante del modelo, en lugar de necesitar palabras iniciales, el modelo necesitar√° un n√∫mero espec√≠fico de car√°cteres iniciales. En nuestro caso 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenght = 60\n",
    "sequences = [text[ix-lenght: ix+1] for ix in range(lenght, len(text))]\n",
    "ch_ix = pickle.load(open(\"encoding_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fin de tener una manera num√©rica de manipular la informaci√≥n, codificaremos cada caract√©r por un valor √∫nico otorgado por nuestro programa.\n",
    "\n",
    "Asumiendo que el cuento tiene $S$ sequencias y $E$ car√°cteres por sequencia, transformaremos nuestros datos a fin de tener una matriz $S\\times E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en un lugar de la mancha, de cuyo nombre no quiero acordarme,',\n",
       " 'n un lugar de la mancha, de cuyo nombre no quiero acordarme, ',\n",
       " ' un lugar de la mancha, de cuyo nombre no quiero acordarme, n',\n",
       " 'un lugar de la mancha, de cuyo nombre no quiero acordarme, no',\n",
       " 'n lugar de la mancha, de cuyo nombre no quiero acordarme, no ',\n",
       " ' lugar de la mancha, de cuyo nombre no quiero acordarme, no h',\n",
       " 'lugar de la mancha, de cuyo nombre no quiero acordarme, no ha',\n",
       " 'ugar de la mancha, de cuyo nombre no quiero acordarme, no ha ',\n",
       " 'gar de la mancha, de cuyo nombre no quiero acordarme, no ha m',\n",
       " 'ar de la mancha, de cuyo nombre no quiero acordarme, no ha mu']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2071389"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 35,  0, ..., 34, 27,  6],\n",
       "       [35,  0, 42, ..., 27,  6,  0],\n",
       "       [ 0, 42, 35, ...,  6,  0, 35],\n",
       "       ...,\n",
       "       [46,  0, 30, ...,  0,  0,  0],\n",
       "       [ 0, 30, 23, ...,  0,  0,  0],\n",
       "       [30, 23, 35, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "sequences_int = [[ch_ix[ch] for ch in seq] for seq in sequences]\n",
    "sequences_int = np.array(sequences_int)\n",
    "sequences_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2071389, 61)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_int.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendiendo a Escribir\n",
    "\n",
    "Finalmente, para ense√±arle a nuestro modelo a escribir, modelamos nuestro problema de la siguiente manera: dado $n-1$ car√°cteres, queremos que el modelo estime el $n$-√©simo car√°cter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de una red neuronal, as√≠ como en varios problemas en machine learning, la codificaci√≥n categorica de un valor a un entero puede ocasionar resultados sub√≥ptimos al momento de entrenar el modelo. Para evitar esto, transformaremos cada car√°cter a un vector de dimensi√≥n $C$ (siendo $C$ el n√∫mero de car√°cteres √∫nicos), en el cu√°l todos los elementos de este nuevo vector son 0, excepto por la posici√≥n\n",
    "\n",
    "Por ejemplo, si un caract√©r tiene valor $2$, creamos un vector $[0, 0, 1, \\ldots, 0]$; de igual manera si un car√°cter tiene valor $0$, creamos un vector de la forma $[1, 0, 0, \\ldots, 0]$. Y as√≠ sucesivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = sequences_int[:50,:-1], sequences_int[:50, -1:]\n",
    "\n",
    "X_train = to_categorical(X_train, num_classes=vocab_size)\n",
    "y_train = to_categorical(y_train, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo estas dos consideraciones, obtenemos una matriz $S\\times C$ de car√°cteres por estimar y un arreglo 3-dimensional $S\\times E \\times C$ de datos dependientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 48)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 60, 48)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definimos una peque√±a arquitectura de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 48)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               59600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 48)                4848      \n",
      "=================================================================\n",
      "Total params: 64,448\n",
      "Trainable params: 64,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_input = Input(X_train.shape[1:])\n",
    "X = LSTM(100, activation=\"relu\", return_sequences=False)(X_input)\n",
    "X = Dense(vocab_size, activation=\"softmax\")(X)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 3.8622 - acc: 0.0200\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.8604 - acc: 0.0200\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.8587 - acc: 0.0200\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.8568 - acc: 0.0200\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.8551 - acc: 0.0200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x126024208>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado el modelo, podemos hacer inferencia sobre nuestro nuevo libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding = {val:char for char, val in ch_ix.items()}\n",
    "n_chars = len(ch_ix)\n",
    "seq = \"despues de haber vivido su primera aventura don quijote se sentia\"\n",
    "text_seq = deque([ch for ch in seq], maxlen=lenght)\n",
    "\n",
    "for _ in range(100):\n",
    "    encoded = [ch_ix[ch] for ch in text_seq]\n",
    "    encoded = pad_sequences([encoded], maxlen=lenght, padding=\"pre\")\n",
    "    encoded = to_categorical(encoded, num_classes=n_chars).reshape(1, -1, n_chars)\n",
    "    probs = model.predict(encoded, batch_size=1)\n",
    "    # pred = np.argmax(model.predict(encoded, batch_size=1))\n",
    "    pred = np.random.choice(np.arange(n_chars), p=probs.ravel())\n",
    "    char = decoding[pred]\n",
    "    text_seq.append(char)\n",
    "    seq += char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "despues de haber vivido su primera aventura don quijote se sentia??yv2u'.)roes10v]h(0tn3aho-?uz ;>\"7du-az4-yinj6xs(6 :n?ma,;]gg;'s'4)w0em\" ?hu'stsg1i'goy!e\"(>wsb,uz4\n"
     ]
    }
   ],
   "source": [
    "print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer nuestro modelo no es tan bueno para escribir un libro..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto √∫ltimo se debe a que necesitamos varias √©pocas de entrenamiento para llegar un mejor modelo que pueda escribir un libro. Los siguientes ejemplos muestran la vida del modelo despu√©s de varias √©pocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ~ 5 epochs (5 secuencias):  \n",
    "`despues de haber vivido su primera aventura don quijote se sentia??yv2u'.)roes10v]h(0tn3aho-?uz ;>\"7du-az4-yinj6xs(6 :n?ma,;]gg;'s'4)w0em\" ?hu'stsg1i'goy!e\"(>wsb,uz4`\n",
    "\n",
    "* ~ 50 epochs:   \n",
    "  `despues de haber vivido su primera aventura don quijote se sentias eldeno- uelvimes o`\n",
    "  \n",
    "* ~ 150 epochs:   \n",
    "  `despues de haber vivido su primera aventura don quijote se sentia serentas tan ojo es busa coma estado este amanas. ahardada digustra mando, con somparia de egla fue``\n",
    "  \n",
    "* ~ 190 epochs:   \n",
    "  `despues de haber vivido su primera aventura don quijote se sentia de aris, dilino; ya a oflico el estria don quiso y nuesa.  y si no tenda trezas que tienele y de lg`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
